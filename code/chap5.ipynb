{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "958320d5-6dff-4566-84b8-5bce5ad242f6",
   "metadata": {},
   "source": [
    "# 誤差逆伝播法(back propagation)\n",
    "\n",
    "<!-- ここから生の HTML -->\n",
    "<script\n",
    "  src=\"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"\n",
    "  id=\"MathJax-script\"\n",
    "  async>\n",
    "</script>\n",
    "<!-- ここまで -->\n",
    "\n",
    "- 重みパラメータの勾配の計算方法.\n",
    "  1. 数値微分法(4章)\n",
    "  2. 誤差逆伝播法(5章)\n",
    "      - 数式\n",
    "      - 計算グラフ(computational graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c5dfb6",
   "metadata": {},
   "source": [
    "\n",
    "## 5.1 計算グラフ(computational graph)\n",
    "### 計算グラフ\n",
    "- 計算の過程をグラフによって表したもの. \n",
    "- 複数のノードとエッジ（矢印）から構成. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0f5587",
   "metadata": {},
   "source": [
    "### 5.1.1 計算グラフで解く\n",
    "#### 問1. 太郎君はスーパーで1個100円のリンゴを2個買いました。支払う金額を求めなさい。ただし、消費税が10%適用されるものとする. \n",
    "- この問題を使って、計算グラフを書いてみる. \n",
    "- ルール\n",
    "    - ノ ー ド: 〇で表記. \n",
    "    - 演　  算: 〇の中に書く.\n",
    "    - 途中結果: エッジの上に表記\n",
    "\n",
    "![](5-1.svg)\n",
    "\n",
    "- 計算グラフの流れ\n",
    "    1. リンゴの\"100\"円が「×2」ノードへ流れる\n",
    "    2. \"200\"円になる\n",
    "    3. \"200\"円が「×1.1」ノードへ流れる\n",
    "    4. \"220\"円になる\n",
    "    5. 答えは、220円\n",
    "\n",
    "- 「リンゴの個数」と「消費税」を変数にする場合.\n",
    "    - ノードを「×」へと変更\n",
    "    - 一つのノードに二つが入射する. \n",
    "\n",
    "![](5-2.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816fdead",
   "metadata": {},
   "source": [
    "#### 問2. 太郎君はスーパーで1個100円のリンゴを2個, みかんを3個買いました。リンゴは1個100円、みかんは1個150円です。消費税が10%かかるとして、支払う金額を求めなさい. \n",
    "計算グラフ\n",
    "\n",
    "![](5-3.svg)\n",
    "\n",
    "- 加算ノード「＋」が新たに追加 $\\rightarrow$ リンゴとみかんを合算\n",
    "- 計算グラフの流れ\n",
    "    1. リンゴの\"100\"円と個数である\"2\"が「×」ノードへ流れる.\n",
    "    2. \"200\"円になる\n",
    "    3. みかんの\"150\"円と個数である\"3\"が「×」ノードへ流れる.\n",
    "    4. \"450\"円になる\n",
    "    5. 2.の\"200\"円と4.の\"450\"円が、「＋」ノードへ流れる. \n",
    "    6. \"650\"円になる\n",
    "    7. 6.の\"650\"と消費税の\"1.1\"が「×」ノードへ流れる. \n",
    "    8. \"715\"円になる\n",
    "    5. 答えは、715円\n",
    "- 計算グラフによる解き方\n",
    "  1. 計算グラフを構築する.\n",
    "  2. 計算グラフ上で計算を左から右へ進める.\n",
    "- 左から右へ $\\rightarrow$ **順伝播(forward propagation)**\n",
    "- 右から左へ $\\rightarrow$ **逆伝播(backward propagation)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db4ddfc",
   "metadata": {},
   "source": [
    "### 5.1.2 局所的な計算\n",
    "- 計算グラフ特徴：「**局所的な計算**」を伝播することによって、最終的な結果を得ることができる. \n",
    "    - ノードに対する「入力」が分かれば「出力」を生成できる. \n",
    "    - ノード毎に「局所的な計算」をし、次のノードへと伝達するだけでいい. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c7bd4f",
   "metadata": {},
   "source": [
    "### 5.1.3 なぜ計算グラフで解くのか？\n",
    "- 計算グラフで解く理由$\\rightarrow$ 逆伝播によって「**微分**」を効率よく計算できる!!\n",
    "- 問1の再考\n",
    "    - リンゴの値段を$x$, 支払金額を$L$とする. \n",
    "    - 「リンゴの値段に関する支払金額の微分」= $\\frac{\\partial L}{\\partial x}$\n",
    "    - 計算グラフ上での**逆伝播**によって、微分を求めることができる. \n",
    "\n",
    "    ![](5-5.svg)\n",
    "\n",
    "    - 逆伝播\n",
    "        - 順方向とは逆向きの矢印\n",
    "        - 「局所的な微分」を伝達\n",
    "        - 「1 $\\rightarrow$ 1.1 $\\rightarrow$ 2.2」\n",
    "        - 「リンゴが微少量増加したら、最終的な金額はその2.2倍になる」という意味. \n",
    "    - こうして、順伝播と逆伝播によって、各変数の微分の値を効率よく求めることができる. \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3b7e36",
   "metadata": {},
   "source": [
    "## 5.2 連鎖律\n",
    "- 「局所的な微分」を伝達する原理　$\\rightarrow$ **連鎖率(chain law)**\n",
    "\n",
    "### 5.2.1 計算グラフの逆伝播\n",
    "- $y=f(x)$という計算の逆伝播\n",
    "- 信号Eに対して, $\\frac{\\partial y}{\\partial x}$を乗算し、次のノードへと伝達.\n",
    "\n",
    "![](5-6.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586505bf",
   "metadata": {},
   "source": [
    "### 5.2.2 連鎖律とは\n",
    "- 合成関数(複数の関数によって構成される関数)\n",
    "$$\n",
    "\\begin{aligned}\n",
    "z &= t^2\\\\\n",
    "t &= x + y\n",
    "\\end{aligned}\n",
    "\\tag{5.1}\n",
    "$$\n",
    "\n",
    "- 連鎖率の原理(=合成関数の微分についての性質)\n",
    "  > ある関数が合成関数で表される場合、その合成関数の微分は、合成関数を構成するそれぞれの関数の微分の積によって表すことができる。\n",
    "\n",
    "- (5.1)式でいえば、$\\frac{\\partial z}{\\partial x}$は、$\\frac{\\partial y}{\\partial t}$ と$\\frac{\\partial t}{\\partial x}$の積によって表すことができる. \n",
    "$$\n",
    "\\cfrac{\\partial z}{\\partial x} = \\cfrac{\\partial z}{\\partial t} \\cfrac{\\partial t}{\\partial x}\n",
    "\\tag{5.2}\n",
    "$$\n",
    "- 連鎖律を使って、(5.2)式の微分$\\frac{\\partial z}{\\partial x}$を求めるために、局所的な微分（偏微分）を求める.\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\cfrac{\\partial z}{\\partial t} = 2t \\\\\n",
    "\\cfrac{\\partial t}{\\partial x} = 1\n",
    "\\end{aligned}\n",
    "\\tag{5.3}\n",
    "$$\n",
    "- 従って、$\\frac{\\partial z}{\\partial x}$を計算すると、\n",
    "$$\n",
    "\\cfrac{\\partial z}{\\partial x} = \\cfrac{\\partial z}{\\partial t} \\cfrac{\\partial t}{\\partial x} = 2t \\cdot 1 = 2(x+y)\n",
    "\\tag{5.4}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4db4be",
   "metadata": {},
   "source": [
    "### 5.2.3 連鎖律と計算グラフ\n",
    "- (5.4)式で行った連鎖律の計算を、計算グラフで表す. \n",
    "\n",
    "![](5-7.svg)\n",
    "\n",
    "- 計算の順伝播\n",
    "    - 右から左へと、信号を伝播\n",
    "    - ノードへの入力信号に対して、局所的な微分（偏微分）を乗算して、次のノードへと伝達. \n",
    "    - 一番左の結果は、「xに関するzの微分」に対応. \n",
    "\n",
    "![](5-8.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97277352",
   "metadata": {},
   "source": [
    "## 5.3 逆伝播\n",
    "ここでは、「＋」や「×」などの演算を例に、逆伝播の仕組みについて説明する.\n",
    "### 5.3.1 加算ノードの逆伝播\n",
    "- $z=x+y$について考える. \n",
    "- 解析的に微分すると、ともに$\\frac{\\partial z}{\\partial x}, \\frac{\\partial z}{\\partial y}$は共に1となる. \n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\cfrac{\\partial z}{\\partial x} = 1 \\\\\n",
    "\\cfrac{\\partial z}{\\partial y} = 1\n",
    "\\end{aligned}\n",
    "\\tag{5.5}\n",
    "$$\n",
    "- 計算グラフで表すと、次のようになる. \n",
    "  - 上流から伝わった微分を、そのまま下流へ流すだけ.\n",
    "  - 下流に$\\frac{\\partial L}{\\partial x},\\frac{\\partial L}{\\partial y}$ の値を伝播させていく. \n",
    "\n",
    "![](5-9a.svg)\n",
    "\n",
    "![](5-9b.svg)\n",
    "\n",
    "- 具体例 : $10+5=15$を加算ノードに通すと……？\n",
    "  - 加算ノードの順伝播は、入力信号を次のノードへ出力するだけなので、下記のようになる.\n",
    "\n",
    "![](5-11a.svg)\n",
    "\n",
    "![](5-11b.svg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b687eba2",
   "metadata": {},
   "source": [
    "### 5.3.2 乗算ノードの逆伝播\n",
    "- $z=xy$について考える. \n",
    "- 解析的に微分すると、ともに$\\frac{\\partial z}{\\partial x}=y, \\frac{\\partial z}{\\partial y}=x$となる. \n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\cfrac{\\partial z}{\\partial x} = y \\\\\n",
    "\\cfrac{\\partial z}{\\partial y} = x\n",
    "\\end{aligned}\n",
    "\\tag{5.6}\n",
    "$$\n",
    "- 計算グラフで表すと、次のようになる. \n",
    "  - 上流の値に、順伝播の際の入力信号を”ひっくり返した値”を乗算して下流へ流す. \n",
    "  - 順伝播のときの入力信号が必要. $\\rightarrow$ 実装時には、入力信号を保持する仕組みが必要!!\n",
    "\n",
    "### 5.3.3 リンゴの例\n",
    "- 解きたい問題\n",
    "  - **リンゴの値段、リンゴの個数、消費税の三つの変数が、それぞれ最終的な支払金額にどのように影響するか**、ということ. \n",
    "  - (順伝播の値を使いながら)逆伝播を使って、計算グラフを作成. \n",
    "\n",
    "![](5-14.svg)\n",
    "\n",
    "- 結果\n",
    "  1. リンゴの値段 : 2.2\n",
    "  2. リンゴの個数 : 110\n",
    "  3. 消費税 : 200\n",
    "\n",
    "  の大きさで、最終的な支払金額に影響を与える(但し、消費税と金額はスケールが違うので注意).\n",
    "\n",
    "- 「リンゴとみかんの買い物」の逆伝播を導く. \n",
    "\n",
    "![](5-15.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06d131b",
   "metadata": {},
   "source": [
    "## 5.4 単純なレイヤの実装\n",
    "加算ノード、乗算ノードをそれぞれ加算レイヤ、乗算レイヤとして実装.\n",
    "### 5.4.1 乗算レイヤの実装\n",
    "- MulLayer\n",
    "  - インスタンス変数(入力信号を保持するために必要)\n",
    "    - self.x\n",
    "    - self.y\n",
    "  - メソッド\n",
    "    - \\_\\_init\\_\\_\n",
    "    - forward()  →　順方向に入力信号を伝播.\n",
    "    - backward()　→　forwardとは逆方向に、微分を計算. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e077e078",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir) # ＋親ディレクトリ\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb8a2330-82f3-499d-9291-bd63f1ef1c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mulayer: # 乗算レイヤ\n",
    "    def __init__(self):\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "    def forward(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        out = x*y\n",
    "        return out\n",
    "    def backward(self, dout): #dout : 上流から伝わってきた微分\n",
    "        dx = dout * self.y\n",
    "        dy = dout * self.x\n",
    "        return dx, dy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6257e0",
   "metadata": {},
   "source": [
    "「リンゴの買い物」に照らし合わせると……\n",
    "\n",
    "![](5-16.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "767b6788-6f17-48c2-9e39-0a855a675f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward: 220\n",
      "backward: 2.2, 110, 200\n"
     ]
    }
   ],
   "source": [
    "apple = 100\n",
    "apple_num = 2\n",
    "tax = 1.1\n",
    "\n",
    "# layer\n",
    "mul_apple_layer = Mulayer()\n",
    "mul_tax_layer = Mulayer()\n",
    "\n",
    "# forward(順伝播)\n",
    "apple_price = mul_apple_layer.forward(apple, apple_num)     \n",
    "price = mul_tax_layer.forward(apple_price, tax)                 \n",
    "\n",
    "print(f\"forward: {price:.0f}\")\n",
    "\n",
    "# backward(逆伝播)\n",
    "dprice = 1 # 最後の乗算ノードからの出力と最終値は同じ（微分は1）\n",
    "dapple_price, dtax = mul_tax_layer.backward(dprice)\n",
    "dapple, dapple_num = mul_apple_layer.backward(dapple_price)\n",
    "\n",
    "print(f\"backward: {dapple}, {dapple_num:.0f}, {dtax}\")  # 図5.16の結果と一致!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6ce2d6",
   "metadata": {},
   "source": [
    "### 5.4.2 加算レイヤの実装\n",
    "<style>\n",
    "  r { color: red; }\n",
    "</style>\n",
    "\n",
    "- AddLayer\n",
    "    - インスタンス変数\n",
    "        - <r>なし！</r>(加算レイヤは入力値を保持する必要がない)\n",
    "    - メソッド\n",
    "        - \\_\\_init\\_\\_\n",
    "        - forward()\n",
    "        - backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6027bdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddLayer:\n",
    "    def __init__(self):\n",
    "        pass    # 入力信号を保持する必要がない\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        out = x+y\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):   # 上流からの微分をそのまま下流へ\n",
    "        dx = dout * 1\n",
    "        dy = dout * 1\n",
    "        return dx, dy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9101fe",
   "metadata": {},
   "source": [
    "「リンゴ２個とみかん３個の買い物」に照らし合わせると……\n",
    "\n",
    "![](5-17.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b99d89e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "715\n",
      "2.2, 110.0, 3.3, 165.0, 650\n"
     ]
    }
   ],
   "source": [
    "apple = 100\n",
    "apple_num = 2\n",
    "orange = 150\n",
    "orange_num = 3\n",
    "tax = 1.1\n",
    "\n",
    "# layer\n",
    "mul_apple_layer = Mulayer()\n",
    "mul_orange_layer = Mulayer()\n",
    "add_apple_orange = AddLayer()\n",
    "mul_tax_layer = Mulayer()\n",
    "\n",
    "# forward\n",
    "apple_price = mul_apple_layer.forward(apple, apple_num)\n",
    "orange_price = mul_orange_layer.forward(orange, orange_num)\n",
    "all_price = add_apple_orange.forward(apple_price, orange_price)\n",
    "price = mul_tax_layer.forward(all_price, tax)\n",
    "\n",
    "# backward\n",
    "dprice = 1\n",
    "dall_price, dtax = mul_tax_layer.backward(dprice)\n",
    "dapple_price, dorange_price = add_apple_orange.backward(dall_price)\n",
    "dorange, dorange_num = mul_orange_layer.backward(dorange_price)\n",
    "dapple, dapple_num = mul_apple_layer.backward(dapple_price)\n",
    "\n",
    "print(f\"{price:.0f}\")\n",
    "print(f\"{dapple}, {dapple_num:.1f}, {dorange:.1f}, {dorange_num:.1f}, {dtax}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ed0a4e",
   "metadata": {},
   "source": [
    "## 5.5 活性化関数レイヤの実装\n",
    "- 計算グラフ　-> ニューラルネットワークへ\n",
    "- ニューラルネットワークを構成する「層(layer)」を一つのクラスとして実装\n",
    "\n",
    "### 5.5.1 ReLU(Rectified Linear Unit)レイヤ\n",
    "- 定義式\n",
    "    $$\n",
    "    y = \n",
    "    \\begin{cases}\n",
    "    x     & (x > 0),\\\\\n",
    "    0     & (x \\le 0).\n",
    "    \\end{cases}\n",
    "    \\tag{5.7}\n",
    "    $$\n",
    "- xに関するyの微分\n",
    "    $$\n",
    "    \\cfrac{\\partial y}{\\partial x} = \n",
    "    \\begin{cases}\n",
    "    1     & (x > 0),\\\\\n",
    "    0     & (x \\le 0).\n",
    "    \\end{cases}\n",
    "    \\tag{5.8}\n",
    "    $$\n",
    "    - 下流に対して、x(順伝播時の入力)が0より大きければ1を、0以下であれば流さない(<span style=\"color:red;\">信号がストップ</span>). \n",
    "    - 「**スイッチ**」のように動作する。\n",
    "        - 順伝播時に電流が流れている(x >  0) -> スイッチON(逆伝播時にも微分は1)\n",
    "        - 順伝播時に電流が流れてない(x <= 0) -> スイッチON(逆伝播時にも微分は<span style=\"color:red;\">0</span>)\n",
    "\n",
    "\n",
    "![](5-18a.svg)\n",
    "\n",
    "![](5-18b.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebe4705",
   "metadata": {},
   "source": [
    "#### 実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43808c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReLUレイヤの実装\n",
    "class Relu:\n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.mask = (x <= 0) # bool型配列\n",
    "        out = x.copy()\n",
    "        out[self.mask] = 0   # trueの要素に0を代入\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dout[self.mask] = 0     # x <= 0で偏微分は0\n",
    "        dx = dout * 1           # x >  0で　〃　　1\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bc066c",
   "metadata": {},
   "source": [
    "#### インスタンス変数maskについて\n",
    "- mask : True/False からなるNumpy配列\n",
    "- 順伝播の入力であるxの要素で、0以下の場所をTrue, 0より大きい場所をFalseとして保持. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "839cfd84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  -0.5]\n",
      " [-2.   3. ]]\n",
      "[[False  True]\n",
      " [ True False]]\n"
     ]
    }
   ],
   "source": [
    "# テスト(bool型配列)\n",
    "x = np.array([[1.0, -0.5], [-2.0, 3.0]])\n",
    "print(x)\n",
    "mask = (x<=0)\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc9bd20",
   "metadata": {},
   "source": [
    "### 5.5.2 Sigmoidレイヤ\n",
    "Sigmoid関数を実装していく. \n",
    "- 定義式\n",
    "    $$\n",
    "    y = \n",
    "    \\cfrac{1}{1+\\exp (-x)}\n",
    "    \\tag{5.7}\n",
    "    $$\n",
    "- 計算グラフによる表現\n",
    "\n",
    "![](5-19.svg)\n",
    "\n",
    "- 除算ノード「/」($y=\\frac{1}{x}$)について\n",
    "    $$\n",
    "        \\cfrac{\\partial y}{\\partial x} = -\\cfrac{1}{x^2} = -y^2\n",
    "        \\tag{5.10}\n",
    "    $$\n",
    "    より、上流の値に対して、$-y^2$を乗算して下流へ伝播させればよい. \n",
    "- expノード「exp」について\n",
    "    $$\n",
    "    \\cfrac{\\partial y}{\\partial x} = \n",
    "    \\exp(x)\n",
    "    \\tag{5.11}\n",
    "    $$\n",
    "- これらを、図5.19に沿って逆伝播を求めていくと、計算グラフは次のようになる. \n",
    "\n",
    "![](5-20.svg)\n",
    "\n",
    "- 真ん中の部分をグループ化した「sigmoid」ノードとして書くと、次のようになる. \n",
    "\n",
    "![](5-21.svg)\n",
    "\n",
    "- $\\frac{\\partial L}{\\partial y} y^2 \\exp(-x)$を、さらに整理して計算する. \n",
    "    $$\n",
    "    \\begin{aligned}\n",
    "    \\cfrac{\\partial y}{\\partial x} &= \n",
    "    \\cfrac{\\partial L}{\\partial y} \\cfrac{1}{(1+\\exp (-x))^2} \\exp(-x)\\\\\n",
    "    &= \\cfrac{\\partial L}{\\partial y} \\cfrac{1}{(1+\\exp (-x))^2} \\cfrac{\\exp(-x)}{1+\\exp(-x)}\\\\\n",
    "    &= \\cfrac{\\partial L}{\\partial y} y(1-y)\n",
    "    \\end{aligned}\n",
    "    \\tag{5.12}\n",
    "    $$\n",
    "- 従って、Sigmoidレイヤの逆伝播は、順伝播の出力だけから計算できる. \n",
    "\n",
    "![](5-22.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eddbfba",
   "metadata": {},
   "source": [
    "#### 実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80cab8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoidレイヤの実装\n",
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        self.out = None     # ノードからの出力信号は保持する\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = 1/(1+np.exp(-x))\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):   \n",
    "        dx = dout * (1.0 - self.out) * self.out\n",
    "        #   ∂L/∂x * ( 1   -    y )   *    y\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bff3db4",
   "metadata": {},
   "source": [
    "## 5.6 Affine/Softmaxレイヤの実装\n",
    "### 5.6.1 Affineレイヤ\n",
    "- ニューラルネットワークの順伝播 -> 重み付き信号の総和を行列の積で計算.\n",
    "- np.dotを用いる. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b2652d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2,)\n",
      "(2, 3)\n",
      "(3,)\n",
      "[0.89118347 0.37067919 0.21076387]\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "X = np.random.rand(2)       # 入力\n",
    "W = np.random.rand(2, 3)    # 重み\n",
    "B = np.random.rand(3)       # バイアス\n",
    "\n",
    "print(X.shape)\n",
    "print(W.shape)\n",
    "print(B.shape)\n",
    "\n",
    "Y = np.dot(X, W) + B \n",
    "print(Y)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7559f055",
   "metadata": {},
   "source": [
    "### ※Affine変換\n",
    "- 線形変換と平行移動を組み合わせた変換.\n",
    "\n",
    "    $Y = X\\cdot W + B$\n",
    "    - $X\\cdot W$ : 線形変換\n",
    "    - $B$  : 平行移動\n",
    "- 変換前の座標を(x,y), 変換後の座標を(u,v)とすると、\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "u \\\\\n",
    "v\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "a & b \\\\\n",
    "c & d\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "x \\\\\n",
    "y\n",
    "\\end{bmatrix}\n",
    "+\n",
    "\\begin{bmatrix}\n",
    "e \\\\\n",
    "f\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "- 3×3行列を使うと、一つの積で完結できる. \n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "u \\\\\n",
    "v \\\\\n",
    "1\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "a & b & e \\\\\n",
    "c & d & f \\\\\n",
    "0 & 0 & 1\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "x \\\\\n",
    "y \\\\ \n",
    "1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "- アフィン変換の例\n",
    "    - 拡大/縮小(X軸方向の拡大率$S_x$, Y軸方向の拡大率$S_y$)\n",
    "        $$\n",
    "        \\begin{bmatrix}\n",
    "        u \\\\\n",
    "        v \\\\\n",
    "        1\n",
    "        \\end{bmatrix}\n",
    "        =\n",
    "        \\begin{bmatrix}\n",
    "        S_x & 0 & 0 \\\\\n",
    "        0 & S_y & 0 \\\\\n",
    "        0 & 0 & 1\n",
    "        \\end{bmatrix}\n",
    "        \\begin{bmatrix}\n",
    "        x \\\\\n",
    "        y \\\\ \n",
    "        1\n",
    "        \\end{bmatrix}\n",
    "        =\n",
    "        \\begin{bmatrix}\n",
    "        S_x x \\\\ \n",
    "        S_y y \\\\ \n",
    "        1\n",
    "        \\end{bmatrix}\n",
    "        $$\n",
    "    - 平行移動(X軸方向へ$\\gamma_x$, Y軸方向へ$\\gamma_y$だけ移動)\n",
    "        $$\n",
    "        \\begin{bmatrix}\n",
    "        u \\\\\n",
    "        v \\\\\n",
    "        1\n",
    "        \\end{bmatrix}\n",
    "        =\n",
    "        \\begin{bmatrix}\n",
    "        1 & 0 & \\gamma_x \\\\\n",
    "        0 & 1 & \\gamma_y \\\\\n",
    "        0 & 0 & 1\n",
    "        \\end{bmatrix}\n",
    "        \\begin{bmatrix}\n",
    "        x \\\\\n",
    "        y \\\\ \n",
    "        1\n",
    "        \\end{bmatrix}\n",
    "        =\n",
    "        \\begin{bmatrix}\n",
    "        x + \\gamma_x \\\\ \n",
    "        y + \\gamma_y \\\\ \n",
    "        1\n",
    "        \\end{bmatrix}\n",
    "        $$\n",
    "    - 回転(原点周りに$\\theta^\\circ$回転)\n",
    "        $$\n",
    "        \\begin{bmatrix}\n",
    "        u \\\\\n",
    "        v \\\\\n",
    "        1\n",
    "        \\end{bmatrix}\n",
    "        =\n",
    "        \\begin{bmatrix}\n",
    "        \\cos\\theta & -\\sin\\theta & 0 \\\\\n",
    "        \\sin\\theta &  \\cos\\theta & 0 \\\\\n",
    "        0 & 0 & 1\n",
    "        \\end{bmatrix}\n",
    "        \\begin{bmatrix}\n",
    "        x \\\\\n",
    "        y \\\\ \n",
    "        1\n",
    "        \\end{bmatrix}\n",
    "        =\n",
    "        \\begin{bmatrix}\n",
    "        x\\cos\\theta - y\\sin\\theta  \\\\ \n",
    "        x\\sin\\theta + y\\cos\\theta \\\\\n",
    "        1\n",
    "        \\end{bmatrix}\n",
    "        $$\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04afca2",
   "metadata": {},
   "source": [
    "#### 逆伝播の計算\n",
    "- これまでは「スカラ値」がノード間を流れていたが、Affineレイヤでは、「行列」がノードを伝播. \n",
    "- 計算グラフは次のようになる. \n",
    "\n",
    "![](5-24.svg)\n",
    "\n",
    "- 逆伝播（偏微分）は次のようになる. \n",
    "    $$\n",
    "    \\begin{aligned}\n",
    "    \\cfrac{\\partial y}{\\partial \\mathbf{X}} = \\cfrac{\\partial L}{\\partial \\mathbf{Y}} \\cdot \\mathbf{W}^T \\\\\n",
    "    \\cfrac{\\partial y}{\\partial \\mathbf{W}} = \\mathbf{X}^T \\cdot \\cfrac{\\partial L}{\\partial \\mathbf{Y}}\\\\\n",
    "    \\end{aligned}\n",
    "    \\tag{5.13}\n",
    "    $$\n",
    "    - 成分表示による導出.\n",
    "        $$\n",
    "        Y_{ij} = \\sum_k X_{ik}W_{kj}\n",
    "        $$\n",
    "        損失$L$を$Y_{ij}$によって微分すると、\n",
    "        $$\n",
    "        \\cfrac{\\partial L}{\\partial X_{ik}} = \\sum_j \\cfrac{\\partial L}{\\partial Y_{ij}} \\cfrac{\\partial Y_{ij}}{\\partial X_{ik}} = \\sum_j \\cfrac{\\partial L}{\\partial Y_{ij}} W_{kj} = \\sum_j \\cfrac{\\partial L}{\\partial Y_{ij}} (W^T)_{jk} = \\left[ \\cfrac{\\partial L}{\\partial \\mathbf{Y}}\\mathbf{W}^T \\right]_{ik}\n",
    "        $$\n",
    "        同様に、$W_{kj}$によって微分すると、\n",
    "        $$\n",
    "        \\cfrac{\\partial L}{\\partial W_{kj}} = \\sum_i \\cfrac{\\partial L}{\\partial Y_{ij}} \\cfrac{\\partial Y_{ij}}{\\partial W_{kj}} = \\sum_i \\cfrac{\\partial L}{\\partial Y_{ij}} X_{ik}\n",
    "        $$\n",
    "        これはスカラー同士の掛け算であるから、積の順番を入れ替えてよく、\n",
    "        $$\n",
    "        = \\sum_i X_{ik}\\cfrac{\\partial L}{\\partial Y_{ij}}  =  \\sum_i (X^T)_{ki}\\cfrac{\\partial L}{\\partial Y_{ij}} = \\left[ \\mathbf{X}^T \\cfrac{\\partial L}{\\partial \\mathbf{Y}} \\right]_{kj}\n",
    "        $$\n",
    "        以上導出終わり. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996cf03e",
   "metadata": {},
   "source": [
    "- 計算グラフでの逆伝播は次のようになる.\n",
    "\n",
    "![](5-25.svg)\n",
    "\n",
    "- 注意点\n",
    "    - (M,)は(1,M)のようにして、行列の積として考えると分かりやすい. numpyの一次元リストは、\"行列のようなもの”. \n",
    "    - 各変数の形状について、$\\mathbf{X}$と$\\frac{\\partial L}{\\partial \\mathbf{X}}$、および$\\mathbf{W}$と$\\frac{\\partial L}{\\partial \\mathbf{W}}$は同じ形状である(ベクトルによる偏微分というのは結局, 各成分ごとに偏微分をすることなので).\n",
    "    $$\n",
    "    \\begin{aligned}\n",
    "    \\mathbf{X} &= (x_0, x_1, \\dots, x_n) \\\\ \n",
    "    \\cfrac{\\partial L}{\\partial \\mathbf{X}} &= (\\cfrac{\\partial L}{\\partial x_0}, \\cfrac{\\partial L}{\\partial x_1}, \\cdots,\\cfrac{\\partial L}{\\partial x_n})\n",
    "    \\end{aligned}\n",
    "    \\tag{5.15}\n",
    "    $$\n",
    "\n",
    "\n",
    "![](5-26.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda7092a",
   "metadata": {},
   "source": [
    "### 5.6.2 バッチ版Affineレイヤ\n",
    "- Affineレイヤ\n",
    "    - 入力$\\mathbf{X}$は一つのデータ.\n",
    "- バッチ版Affineレイヤ\n",
    "    - 入力$\\mathbf{X}$はN個のまとまったデータ(バッチ). \n",
    "#### 変更点\n",
    "- 計算グラフでは、入力である$\\mathbf{X}$の形状が$(N,2)$となる.\n",
    "- バイアスは、それぞれのデータに対して加算される.\n",
    "    - それぞれのデータの逆伝播の値が、バイアスの要素($b_1, b_2, \\cdots, b_N$)に集約される(データごとに合算される)必要がある. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31e696d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0]\n",
      " [10 10 10]]\n",
      "[[ 1  2  3]\n",
      " [11 12 13]]\n"
     ]
    }
   ],
   "source": [
    "# 順伝播\n",
    "X_dot_W = np.array([[0,0,0],[10,10,10]]) \n",
    "B = np.array([1,2,3])\n",
    "print(X_dot_W)\n",
    "\n",
    "print(X_dot_W + B)  # 順伝播では、（当然だが）X_dot_W[0], X_dot_W[1]のそれぞれに、バイアスBが加算される. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32e50c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "[5 7 9]: axis=0\n",
      "[ 6 15]: axis=1\n"
     ]
    }
   ],
   "source": [
    "# 逆伝播\n",
    "dY = np.array([[1,2,3,],[4,5,6,]])\n",
    "print(dY)\n",
    "\n",
    "dB = np.sum(dY, axis=0) # axis=0(同じ列)で合計 -> dB.shape=(3,)\n",
    "print(f\"{dB}: axis=0\")\n",
    "\n",
    "dB = np.sum(dY, axis=1) # axis=1(同じ行)\n",
    "print(f\"{dB}: axis=1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5120d21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Affine:\n",
    "    def __init__(self, W, b):\n",
    "        self.W = W      # 重み W: (2, 3)\n",
    "        self.b = b      # バイアス b: (3,)\n",
    "        self.x = None   # 入力信号\n",
    "        self.dW = None  # W の勾配\n",
    "        self.db = None  # b の勾配\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: (N, 2)\n",
    "        self.x = x\n",
    "        out = np.dot(x, self.W) + self.b  # b は (3,) がブロードキャストされ、(N,3)になる\n",
    "        return out  #(N, 3)\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        # dout: ∂L/∂Y 上流からの微分 (N, 3)\n",
    "        dx = np.dot(dout, self.W.T)           # (N, 2)\n",
    "        self.dW = np.dot(self.x.T, dout)      # (2, 3)\n",
    "        # サンプルごとの dout を全て足し合わせる <- \"それぞれのデータの逆伝播値がバイアスの要素に集約\" \n",
    "        self.db = np.sum(dout, axis=0)        # (3,)\n",
    "        return dx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e472d656",
   "metadata": {},
   "source": [
    "### 5.6.3　Softmax-with-Lossレイヤ(出力層)\n",
    "#### Softmax関数\n",
    "- 入力された値を正規化して出力する.\n",
    "- 手書き認識の際は、10クラス分類を行うため、Softmaxレイヤへの入力は10個あることになる. \n",
    "- 通常、「推論」では使用せず「学習」で使用する.\n",
    "-   $\n",
    "    \\left\\{\n",
    "    \\begin{array}{l}\n",
    "    \\text{\\small スコア: 正規化しない出力結果}\\\\\n",
    "    \\text{\\small 確　率: 正規化された出力結果}\n",
    "    \\end{array}\n",
    "    \\right.\n",
    "    $\n",
    "    - 学習時：スコア -> Softmax　-> 確率 -> Cross Entropyなど -> パラメタ更新\n",
    "    - 推論時：スコア -> そのまま最大値がほしい.\n",
    "\n",
    "![](5-30.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a624927",
   "metadata": {},
   "source": [
    "#### 計算グラフ\n",
    "\n",
    "-   順伝播\n",
    "    $\n",
    "    \\colon\n",
    "    \\left\\{\n",
    "    \\begin{array}{l}\n",
    "    {\\small (y_1,y_2,y_3)\\colon \\text{Softmaxレイヤの出力}},\\\\\n",
    "    {\\small (t_1,t_2,t_3)\\colon \\text{教師ラベル}}\n",
    "    \\end{array}\n",
    "    \\right.\n",
    "    $\n",
    "- 逆伝播$\\colon(y_1-t_1, y_2-t_2, y_3-t_3)$\n",
    "- ニューラルネットワークの逆伝播では、この<span style=\"color:red;\">差分(誤差)が前レイヤへと伝わっていく</span>. <- 重要な性質\n",
    "- もともと、Cross Entropy Error はこうなるように設計された関数. \n",
    "    - 回帰問題では、出力層に「恒等関数」を用い、損失関数として「二乗和誤差」を用いるが、これも同様の理由による. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7618347e",
   "metadata": {},
   "source": [
    "#### 実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b34a81dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.functions import *  # softmax, cross entropy error\n",
    "\n",
    "class SoftmaxWithLoss:\n",
    "    def __init__(self):\n",
    "        self.loss = None # 損失\n",
    "        self.y = None # softmaxの出力\n",
    "        self.x = None # 教師データ(one-hot vector)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        self.t = t\n",
    "        self.t = softmax(x)\n",
    "        self.loss = cross_entropy_error(self.y, self.t)\n",
    "        return self.loss \n",
    "    \n",
    "    def backward(self, dout=1): \n",
    "        batch_size = self.t.shape[0]\n",
    "        dx = (self.y - self.t) / batch_size     # データ一個あたりの誤差を伝播\n",
    "        return dx "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae17f1b0",
   "metadata": {},
   "source": [
    "## 5.7 誤差逆伝播法の実装\n",
    "前節で実装したレイヤを組み合わせることにより、ニューラルネットワークを構築する. \n",
    "### 5.7.1 ニューラルネットワークの学習の全体図\n",
    "#### 前提  \n",
    "ニューラルネットワークには, \n",
    "$\n",
    "\\left\\{\n",
    "\\begin{array}{l}\n",
    "{\\small \\text{1. 重み}},\\\\\n",
    "{\\small \\text{2. バイアス}}\n",
    "\\end{array}\n",
    "\\right.\n",
    "$\n",
    "がある. この重みとバイアスを、**訓練データに適応するように調整**することを、「学習」と呼ぶ.\n",
    "#### 学習の手順\n",
    "1. ミニバッチ  \n",
    "訓練データの中からランダムに一部のデータを選び出す. \n",
    "2. 勾配の算出  \n",
    "各重みパラメタに関する損失関数の勾配を求める.       $\\leftarrow$ $\n",
    "\\left\\{\n",
    "\\begin{array}{l}\n",
    "{\\small \\text{4章: 数値微分}},\\\\\n",
    "{\\small \\text{5章: **誤差逆伝播法**}}\n",
    "\\end{array}\n",
    "\\right.\n",
    "$\n",
    "3. パラメタの更新  \n",
    "重みパラメタを勾配方向に微少量だけ更新する.\n",
    "4. 繰り返す  \n",
    "1~3を繰り返す. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b569ebf",
   "metadata": {},
   "source": [
    "### 5.7.2 誤差逆伝播法に対応したニューラルネットワークの実装\n",
    "- Ordered Dict\n",
    "    - ニューラルネットワークのレイヤをOrderedDict(順番付き辞書)として保持する.\n",
    "    - 辞書に追加した要素の順番を覚えることができる. \n",
    "    - $\n",
    "    \\left\\{\n",
    "    \\begin{array}{l}\n",
    "    {\\small \\text{順伝播 : 追加した順にレイヤのforward()を呼び出す.}}\\\\\n",
    "    {\\small \\text{逆伝播 : 逆の順番でレイヤを呼び出す.}}\n",
    "    \\end{array}\n",
    "    \\right.\n",
    "    $ とするだけでよい!!\n",
    "    - レイヤを正しい順番で連結、順番に（または逆順に）呼び出すだけでよい. \n",
    "- レイヤ\n",
    "    - ニューラルネットワークの構成要素を「レイヤ」として実装(モジュール化). \n",
    "    - 大きなネットワークとなっても、レイヤを追加するだけ. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86bb5f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.layers import *  #同階層（＋親ディレクトリ）にある common/layers.py （または common/layers/ パッケージ）から、定義されているクラス・関数を全て読み込み\n",
    "from common.gradient import numerical_gradient # common/gradient.py から numerical_gradient 関数だけを読み込み\n",
    "from collections import OrderedDict \n",
    "\n",
    "\n",
    "class TwoLayerNet:\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size, weight_init_std = 0.01):\n",
    "        # 重みの初期化\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "        self.params['b1'] = np.zeros(hidden_size)\n",
    "        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size) \n",
    "        self.params['b2'] = np.zeros(output_size)\n",
    "\n",
    "        # レイヤの生成\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Affine1'] = Affine(self.params['W1'], self.params['b1'])\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        self.layers['Affine2'] = Affine(self.params['W2'], self.params['b2'])\n",
    "\n",
    "        self.lastLayer = SoftmaxWithLoss()\n",
    "        \n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "    # x:入力データ, t:教師データ\n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        return self.lastLayer.forward(y, t)\n",
    "    \n",
    "    def accuracy(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y, axis=1)\n",
    "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "        \n",
    "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
    "        return accuracy\n",
    "        \n",
    "    # x:入力データ, t:教師データ\n",
    "    def numerical_gradient(self, x, t):\n",
    "        loss_W = lambda W: self.loss(x, t)\n",
    "        \n",
    "        grads = {}\n",
    "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
    "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
    "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
    "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
    "        \n",
    "        return grads\n",
    "        \n",
    "    def gradient(self, x, t):\n",
    "        # forward\n",
    "        self.loss(x, t)\n",
    "\n",
    "        # backward\n",
    "        dout = 1\n",
    "        dout = self.lastLayer.backward(dout)\n",
    "        \n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        # 設定\n",
    "        grads = {}\n",
    "        grads['W1'], grads['b1'] = self.layers['Affine1'].dW, self.layers['Affine1'].db\n",
    "        grads['W2'], grads['b2'] = self.layers['Affine2'].dW, self.layers['Affine2'].db\n",
    "\n",
    "        return grads\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a759cd8d",
   "metadata": {},
   "source": [
    "### 5.7.3 誤差逆伝播法の勾配確認\n",
    "- 誤差逆伝播法 :  計算が早いが、ミスが起きやすい. \n",
    "- 数値微分法   :　計算は遅いが、正確. $\\rightarrow$ 実装の正しさを確認する(<span style=\"color:red;\">勾配確認(gradient check)</span>)ために用いる. \n",
    "\n",
    "#### 実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b846b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1:3.6219084513149784e-10\n",
      "b1:2.2086773514604737e-09\n",
      "W2:5.198418234530328e-09\n",
      "b2:1.3993456773053747e-07\n"
     ]
    }
   ],
   "source": [
    "# gradient_check.py\n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "# データの読み込み\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)    # np.random.randnを使って重み生成　→　毎回出力結果が変わる\n",
    "\n",
    "x_batch = x_train[:3]\n",
    "t_batch = t_train[:3]\n",
    "\n",
    "grad_numerical = network.numerical_gradient(x_batch, t_batch)\n",
    "grad_backprop = network.gradient(x_batch, t_batch)\n",
    "\n",
    "for key in grad_numerical.keys():\n",
    "    diff = np.average( np.abs(grad_backprop[key] - grad_numerical[key]) )\n",
    "    print(key + \":\" + str(diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d51fc45",
   "metadata": {},
   "source": [
    "1e-9~1e-10オーダーの違いなので、ほぼ同じと言える. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9797b88d",
   "metadata": {},
   "source": [
    "### 5.7.4 誤差逆伝播法を使った学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3914b484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "iter:train_acc, test_acc\n",
      "   0:0.11567, 0.11670\n",
      " 600:0.90142, 0.90680\n",
      "1200:0.92302, 0.92650\n",
      "1800:0.93590, 0.93640\n",
      "2400:0.94495, 0.94410\n",
      "3000:0.95203, 0.95080\n",
      "3600:0.95598, 0.95240\n",
      "4200:0.96143, 0.95670\n",
      "4800:0.96355, 0.95930\n",
      "5400:0.96662, 0.96190\n",
      "6000:0.96905, 0.96440\n",
      "6600:0.97122, 0.96680\n",
      "7200:0.97318, 0.96610\n",
      "7800:0.97442, 0.96720\n",
      "8400:0.97655, 0.96970\n",
      "9000:0.97740, 0.96860\n",
      "9600:0.97867, 0.96950\n"
     ]
    }
   ],
   "source": [
    "# train_neuralnet.py\n",
    "\n",
    "# データの読み込み\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "print(x_train.shape)\n",
    "\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "iters_num = 10000   # 繰り返し回数\n",
    "train_size = x_train.shape[0]   # (60000, 784) → 60000\n",
    "batch_size = 100\n",
    "learning_rate = 0.1\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "iter_per_epoch = max(train_size / batch_size, 1)    # 何回バッチ更新すれば全データを一巡するか\n",
    "\n",
    "print(\"iter:train_acc, test_acc\")   # 繰り返し回数, 訓練データセット, 未知データセットをつかった時の精度\n",
    "for i in range(iters_num):\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    \n",
    "    # 勾配\n",
    "    #grad = network.numerical_gradient(x_batch, t_batch)\n",
    "    grad = network.gradient(x_batch, t_batch)\n",
    "    \n",
    "    # 更新\n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "    \n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "\n",
    "    if i % iter_per_epoch == 0:\n",
    "        train_acc = network.accuracy(x_train, t_train)\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print(f\"{i:4d}:{train_acc:.5f}, {test_acc:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "61872b72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# グラフで確認\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs= np.arange(len(train_acc_list)) # 0, 1, ...\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, train_acc_list)\n",
    "plt.plot(epochs, test_acc_list)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Training and Test Accuracy per Epoch\")\n",
    "plt.legend([\"Train\", \"Test\"])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1867e5cc",
   "metadata": {},
   "source": [
    "#### 結果\n",
    "- 初期\n",
    "    - 1エポック後には訓練精度が90%以上　\n",
    "    - 5~6エポックで95%以上 \n",
    "    - 訓練98%, テスト97%程度に収束\n",
    "- 過学習の兆候\n",
    "    - 最終的に、訓練精度(Train) > テスト制度(Test) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58070b7",
   "metadata": {},
   "source": [
    "#### まとめ\n",
    "- 計算グラフを用いれば、計算過程を視覚化できる.\n",
    "- 計算グラフのノードは、局所的な計算によって構成される. \n",
    "- 計算グラフの順伝播は、通常の計算を行う。一方、計算グラフの逆伝播によって、各ノードの微分を求めることができる. \n",
    "- ニューラルネットワークの構成要素をレイヤとして実装することで、重みパラメータの勾配の計算を効率的に求めることができる(誤差逆伝播法).\n",
    "- 数値微分と誤差逆伝播法の結果を比較することで、誤差逆伝播法の実装に誤りがないことを確認できる(勾配確認)\n",
    "- レイヤによるモジュール化によって、ニューラルネットワークでは、レイヤを自由に組み合わせることができ、自分の好きなネットワークを簡単に作れる."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
